{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook is used to give you a demonstration of how image retrieval is performed by using FROMAGe under different prompt settings. Specifically, it aims to prove how compressing complex text input (in this case in the form of a caption and a dialog) into a more clear and compact manner leads to improved capability of retrieving an image that suits the context. The image below describes the procedure in a more comprehensible way.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<img src=\"images_report/visualdialog_scheme.png\" alt=\"Image\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_dialog import dialog_utils\n",
    "from src.image_retrieval_vdialog.scripts import models # changed original code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from fromage.utils import get_image_from_url\n",
    "import openai\n",
    "\n",
    "# Load the FROMAGe model used in the paper.\n",
    "model_dir = './fromage_model/'\n",
    "model = models.load_fromage(model_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dialogs(stories_csv_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(stories_csv_path, encoding='utf8', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataframe\n",
    "dialogs_csv_path = 'visual_dialog/dialogs.csv'\n",
    "dialogs_df = load_dialogs(dialogs_csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get image file by image id\n",
    "def get_image(image_id, show_image=False):\n",
    "    # Loop through all the files in the folder\n",
    "    for file_name in os.listdir(images_path):\n",
    "        # Check if the file name ends with the number and .jpg suffix\n",
    "        if file_name.endswith(str(image_id) + '.jpg'):\n",
    "            # Create the full path to the matching file\n",
    "            # Do something with the file, e.g. print its path\n",
    "            image_path = os.path.join(images_path, file_name)\n",
    "            image = Image.open(image_path).resize((224, 224)).convert('RGB')\n",
    "            if show_image:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.axis('off')\n",
    "                plt.imshow(np.array(image))\n",
    "                plt.show()\n",
    "                        \n",
    "            return image\n",
    "    raise ValueError(f\"Value {image_id} not found in list {images_path}\")\n",
    "\n",
    "def show_image(image):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()\n",
    "\n",
    "instruction = \"\"\"Transform the following caption \n",
    "with a question and answer dialogue about an image \n",
    "into a caption as short as possible while capturing \n",
    "all the information that is given: \"\"\"\n",
    "\n",
    "def gpt_prompt(prompt):\n",
    "    input_prompt = instruction + prompt\n",
    "    print(\"INPUT PROMPT TO GPT\")\n",
    "    print(input_prompt)\n",
    "    # Generate text with a maximum length of 100 tokens\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt= input_prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    adapted_prompt = response.choices[0].text.strip()\n",
    "    return adapted_prompt\n",
    "\n",
    "# Create prompts from dataframe\n",
    "def get_prompt_list(dialogs_df, num_rows, prompt_length, ret_img=True, adapt_gpt_prompt=True, include_Q_A=False):\n",
    "    text = \"\"\n",
    "    dialog, url_dialog, input_dialog_list, url_dialog_list = [], [], [], []\n",
    "    for i in range(num_rows-1):\n",
    "        if int(dialogs_df['round'][i]) == 1:\n",
    "            image_id = dialogs_df['image_id'][i]\n",
    "            caption = dialogs_df['caption'][i]\n",
    "            text += f\"Caption: {caption}. \"\n",
    "            img = get_image(image_id)\n",
    "            # dialog.append(img)\n",
    "        if int(dialogs_df['round'][i]) <= prompt_length:\n",
    "            if include_Q_A == True:\n",
    "                text += f\"Q: {dialogs_df['question'][i]}, \"\n",
    "                text += f\"A: {dialogs_df['answer'][i]}, \"\n",
    "        if dialogs_df['id'][i+1] != dialogs_df['id'][i]:\n",
    "            text = text[:-2]\n",
    "            if adapt_gpt_prompt == True:\n",
    "                text = gpt_prompt(text)\n",
    "                print(\"ADAPTED GPT PROMPT\")\n",
    "                print(text)\n",
    "            if ret_img == True: \n",
    "                dialog.append(text)\n",
    "                dialog.append(img)\n",
    "                url_dialog.append(text)\n",
    "                url_dialog.append(image_id)\n",
    "            else:\n",
    "                dialog.append(img)\n",
    "                dialog.append(text)\n",
    "                url_dialog.append(image_id)\n",
    "                url_dialog.append(text)\n",
    "\n",
    "            # Append the dialog when a new dialog will start next\n",
    "            input_dialog_list.append(dialog)\n",
    "            url_dialog_list.append(url_dialog)\n",
    "            dialog, url_dialog = [], []\n",
    "            text = \"\"\n",
    "\n",
    "    # capture the last row\n",
    "    if prompt_length == 10:\n",
    "        if include_Q_A == True:\n",
    "            text += f\"Q: {dialogs_df['question'][num_rows]}, \"\n",
    "            text += f\"A: {dialogs_df['answer'][num_rows]}\"\n",
    "    if ret_img == True: \n",
    "        url_dialog.append(text)\n",
    "        url_dialog.append(image_id)\n",
    "        dialog.append(text)\n",
    "        dialog.append(img)\n",
    "    else:\n",
    "        url_dialog.append(image_id)\n",
    "        url_dialog.append(text)\n",
    "        dialog.append(img)\n",
    "        dialog.append(text)\n",
    "\n",
    "    url_dialog_list.append(url_dialog)\n",
    "    input_dialog_list.append(dialog)\n",
    "    \n",
    "    return input_dialog_list, url_dialog_list\n",
    "\n",
    "# Display the prompt and retrieve images from their ids\n",
    "def display_prompt(output_list):\n",
    "    for output in output_list:\n",
    "        # Show an image if possible, otherwise display the text\n",
    "        try:\n",
    "            get_image(output, show_image=True)\n",
    "        except:\n",
    "            split_Q = output.split('Q')\n",
    "            for i, line in enumerate(split_Q):\n",
    "                if len(split_Q) > 1:\n",
    "                    if i > 0:\n",
    "                        print(f'Q{line}')\n",
    "                    else:\n",
    "                        print(line)\n",
    "                else:\n",
    "                    print(line)\n",
    "\n",
    "\n",
    "# Display the output of the model, retrieve the images by their url\n",
    "def display_output(story_list):\n",
    "    for element in story_list:\n",
    "        if type(element) == str:\n",
    "            # Show an image if possible, otherwise display the text\n",
    "            try:\n",
    "                image = get_image_from_url(element)\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.axis('off')\n",
    "                plt.imshow(np.array(image))\n",
    "                plt.show()\n",
    "            except:\n",
    "                split_Q = element.split('Q')\n",
    "                for i, line in enumerate(split_Q):\n",
    "                    if len(split_Q) > 1:\n",
    "                        if i > 0:\n",
    "                            print(f'Q{line}')\n",
    "                        else:\n",
    "                            print(line)\n",
    "                    else:\n",
    "                        print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = 3\n",
    "ret_img = True\n",
    "\n",
    "q_a_per_caption = 5\n",
    "num_rows = num_tests * q_a_per_caption * 2\n",
    "\n",
    "if num_rows > len(dialogs_df):\n",
    "    num_rows = len(dialogs_df)\n",
    "\n",
    "dialog_list, url_dialog_list = dialog_utils.get_prompt_list(dialogs_df, num_rows, q_a_per_caption, ret_img, adapt_prompt_gpt, include_Q_A)\n",
    "\n",
    "prompt, prompt_to_save = [], []\n",
    "prompt_list, model_outputs = [], []\n",
    "counter = 0\n",
    "num_pt = 1\n",
    "\n",
    "# Adjustable parameters\n",
    "provide_context = False\n",
    "init_prompt = False\n",
    "\n",
    "for i in range(len(dialog_list)):\n",
    "    # If the number of required examples are met, use the prompt to obtain output from the model\n",
    "    if i % num_pt == num_pt-1:\n",
    "        # Add the last text or image to the model, this is the actual prompt which followed the examples\n",
    "        prompt += [dialog_list[i][0]]\n",
    "        prompt_to_save += [url_dialog_list[i][0]]\n",
    "\n",
    "        if ret_img == True:\n",
    "            num_words = 0\n",
    "            prompt += ['[RET]']\n",
    "            max_num_rets=1\n",
    "        else:\n",
    "            num_words = 300\n",
    "            max_num_rets=0\n",
    "\n",
    "        # Print the amount of performed tests to be able to keep track of the progress\n",
    "        print(\"Test num is\", (i+1)/num_pt)\n",
    "\n",
    "        # Make sure that invalid output will be skipped\n",
    "        try:\n",
    "            image_outputs, output_urls_or_caption = model.generate_for_images_and_texts(list(prompt), max_img_per_ret=3, max_num_rets=max_num_rets, num_words=num_words)\n",
    "            # Add the prompts with the image id to the prompt list and the output containing urls to the model outputs\n",
    "            if image_outputs is not None:\n",
    "                prompt_list.append(prompt_to_save)\n",
    "                model_outputs.append(output_urls_or_caption)\n",
    "                prompt, prompt_to_save = [], []\n",
    "            # Skip if the model did not return images\n",
    "            else:\n",
    "                print(f'Test {(i+1)/num_pt} failed because model returned None.')\n",
    "                prompt, prompt_to_save = [], []\n",
    "                continue\n",
    "        except:\n",
    "            print(f'Test {(i+1)/num_pt} failed because of invalid model output.')\n",
    "            prompt, prompt_to_save = [], []\n",
    "            continue\n",
    "        \n",
    "        # Stop running when the amount of tests is reached\n",
    "        counter += 1\n",
    "        if counter == num_tests:\n",
    "            break\n",
    "\n",
    "    # Provide examples to the model to show it how to handle certain input\n",
    "    else:\n",
    "        if provide_context == True:\n",
    "            # Add the dialogs with url to the prompts that will be stored in a json file\n",
    "            # Add the dialogs with PIL.Image objects to the prompts such that the model can handle them\n",
    "            prompt_to_save += url_dialog_list[i]\n",
    "            prompt += dialog_list[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
