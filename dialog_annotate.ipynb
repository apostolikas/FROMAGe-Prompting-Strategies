{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from visual_dialog import dialog_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 1\n",
    "num_qa = 5\n",
    "# ret_img = True\n",
    "include_Q_A = False\n",
    "gpt_prompt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_annotations_folder = './visual_dialog/annotations'\n",
    "\n",
    "# experiment_name = f'{num_examples}_examples_{num_qa}_qa_{\"ret_img\" if ret_img else \"ret_text\"}_{\"gpt_prompt\" if gpt_prompt else \"nocontext\"}'\n",
    "experiment_name = f'{num_examples}_examples_{num_qa}_qa_{\"inc_QA\" if include_Q_A else \"only_caption\"}{\"_GPT\" if gpt_prompt else \"\"}'\n",
    "\n",
    "baseline_experiment = f'{num_examples}_examples_{num_qa}_qa_{\"inc_QA\" if include_Q_A else \"only_caption\"}'\n",
    "\n",
    "dialog_annotations_csv_path = f'{dialog_annotations_folder}/{experiment_name}.csv'\n",
    "\n",
    "if os.path.exists(dialog_annotations_csv_path):\n",
    "    annotations_df = pd.read_csv(dialog_annotations_csv_path, encoding='utf8')\n",
    "else:\n",
    "    if not os.path.exists(dialog_annotations_folder):\n",
    "        os.makedirs(dialog_annotations_folder)\n",
    "    annotations_df = pd.DataFrame({ \n",
    "        'id': pd.Series(dtype='int'), 'prediction': pd.Series(dtype='int') })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of samples: 50 \n",
      "\n",
      "\n",
      " Done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scan experiment folder without recursion\n",
    "data_path = f'./visual_dialog/{experiment_name}.json'\n",
    "baseline_path = f'./visual_dialog/{baseline_experiment}.json'\n",
    "baseline_prompts = None\n",
    "\n",
    "with open(data_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "if data_path != baseline_path:\n",
    "    with open(baseline_path, 'r') as file:\n",
    "        baseline_data = json.load(file)\n",
    "    baseline_prompts = baseline_data['prompts']\n",
    "\n",
    "# Retrieve the lists\n",
    "prompts = data['prompts']\n",
    "outputs = data['outputs']\n",
    "\n",
    "print(f\"Amount of samples:\", len(prompts), \"\\n\")\n",
    "\n",
    "for i in range(len(prompts)):\n",
    "    # skip annotated story\n",
    "    if i in annotations_df['id'].values:\n",
    "        continue\n",
    "    # if baseline_prompts != None:\n",
    "    if baseline_prompts:\n",
    "        print(\"Unaugmented text input:\")\n",
    "        dialog_utils.display_prompt(baseline_prompts[i])\n",
    "        print(\"\\nGPT augmented text input\\n\")\n",
    "    \n",
    "    dialog_utils.display_prompt(prompts[i])\n",
    "    print('\\n', '=' * 50, '\\n')\n",
    "    dialog_utils.display_output(outputs[i])\n",
    "\n",
    "    prediction = ''\n",
    "    while (prediction != '0') and (prediction != '0.5') and (prediction != '1') and (prediction != '2'):\n",
    "        prediction = input('prediction: 0 (false) - 0.5 (partly correct) - 1 (correct) - 2 (stop)')\n",
    "    \n",
    "    if prediction == '2':\n",
    "        clear_output(wait=False)\n",
    "        break\n",
    "\n",
    "    annotations_df.loc[len(annotations_df)] = [i, float(prediction)]\n",
    "\n",
    "    clear_output(wait=False)\n",
    "\n",
    "annotations_df.to_csv(dialog_annotations_csv_path, encoding='utf8', index=False)\n",
    "\n",
    "print('\\n', 'Done', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./visual_dialog/annotations/1_examples_5_qa_only_caption.csv\n",
      "The accuracy of 50 captions is 54.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "print(dialog_annotations_csv_path)\n",
    "annotations_df = pd.read_csv(dialog_annotations_csv_path)\n",
    "accuracy = round(sum(annotations_df['prediction']) / len(annotations_df['prediction']) * 100, 2)\n",
    "print(f'The accuracy of 50 captions {\"with questions and answers\" if include_Q_A else \"\"}{\"with adjusted prompt by GPT\" if gpt_prompt else \"\"}is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
